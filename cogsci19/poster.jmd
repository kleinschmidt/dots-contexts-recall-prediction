```julia

using Revise

using Weave
Weave.set_chunk_defaults(Dict{Symbol,Any}(
    :results => "hidden",
    :echo => false
))

using 
    LinearAlgebra, 
    Random,
    Statistics

using 
    Plots,
    PlotThemes,
    StatsPlots,
    RecipesBase,
    Colors, 
    Images,
    DataFrames,
    DataFramesMeta,
    Underscore,
    StatsBase,
    ConjugatePriors,
    Particles,
    Distances, 
    Bootstrap

theme(:default, markerstrokecolor=:white)

flip(x::AbstractVector) = reshape(x, (1,:))

const It = Base.Iterators

includet("../modeling.jl")
using .DotLearning
includet("../experiments.jl")
using .Experiments
includet("../plots.jl")

using JLD2
@load "../data/dots2014.jld2" recall pred
# recall data from one subject
one_subj = 4
recall1 = @where(recall, :subjid1 .== one_subj)

# load the prior _parameters_ to get around
@load "../prior_empirical_params.jld2"
prior_optimized = ConjugatePriors.NormalInverseWishart(μ, κ, Λ, ν)
import .Experiments: cosinesim
cosinesim(d) = cosinesim(d,d)

rho(args...) = sqrt(sum(args.^2))

boot_ci(x, f=mean, n=1000, cil=0.95) = confint(bootstrap(f, x, BasicSampling(n)),
                                               BasicConfInt(cil))

nblock = length(unique(recall1[:block]))

block_pallete = LCHab.(60, 60, range(0, 320, length=nblock))

```


# Task

```{julia; label="task-flow-1"}
x, y = -0.3, 0.4
arena([x], [y], color="black")
```

```{julia; label="task-flow-2"}
plot(Gray.(rand(Bool, 100,100)), axis=false, lims=(0,100), aspect_ratio=:equal)
```

```{julia; label="task-flow-3"}
arena([x], [y], color=:white, markerstrokecolor=:black, markersize=5)
annotate!(0,0, text("?", 32))
```


```{julia; label="studied-locations"}

p1 = plot(range(0, 2π, length=100), [2π], proj=:polar, color=:black,
          axis=false, grid=false, legend=false,
          title="Studied locations")
@df recall1 scatter!(p1, :theta, :rho, color=:black, markeralpha=0.5)

p2 = plot(range(0, 2π, length=100), [2π], proj=:polar, color=:black,
          palette = block_pallete, axis=false, grid=false,
          title="Colored by block")
@_ recall1 |>
    by(_, [:block], :theta=>mean, :rho=>mean) |>
    @df(_, plot!(p2, :theta_mean, :rho_mean, color=GrayA(0.5, 0.2)))
@_ recall1 |>
    by(_, [:block], :theta=>mean, :rho=>mean) |>
    @df(_, scatter!(p2, :theta_mean, :rho_mean, group=:block,
                    c=(1:nblock)',
                    markersize=8, markeralpha=0.2))
@df recall1 scatter!(p2, :theta, :rho, group=:block, proj=^(:polar),
                        palette = block_pallete, legend=false)

plot(p1, p2, size=(850, 400))

```

# Behavioral data

```{julia; label="behavioral-data"}
@df recall1 arena(:x, :y, quiver=(:x_resp .- :x, :y_resp .- :y),
                    seriestype=:quiver, color=GrayA(0.0, 1.0), label="Behavior")
```

```{julia; label="known-clusters"}

known_recalled = by(recall, :subjid1) do d
    @_ KnownFilter(prior_optimized) |>
    RecallFilter(_, Matrix(0.01I,2,2)) |>
    filter!(_, extract_data(d, _)) |>
    DataFrame |>
    hcat(d, _) |>
    deletecols!(_, :subjid1) |>
    @transform(_, cosinesim = 1 .- Distances.colwise(CosineDist(), 
                                                   hcat(:x_mod.-:x, :y_mod.-:y)', 
                                                   hcat(:x_resp.-:x, :y_resp.-:y)'))
end

known_recalled1 = @where(known_recalled, :subjid1 .== one_subj)

arena()
@_ known_recalled1 |>
    by(_, :block, :x=>mean, :y=>mean) |>
    @df(_, scatter!(:x_mean, :y_mean, color=block_pallete,
                    markersize=8, markeralpha=0.4))
@df recall1 quiver!(:x, :y, quiver=(:x_resp .- :x, :y_resp .- :y),
                    seriestype=:quiver, color=GrayA(0.0, 0.5), label="Behavior")
@df known_recalled1 plot!(:x, :y, quiver=(:x_mod .- :x, :y_mod .- :y),
                          seriestype=:quiver, group=:block, color=(1:25)',
                          palette = RGBA.(block_pallete, 0.7),
                          label="Cluster bias", markeralpha=0.5)

```

# Results

## Recovering clusters

### Example

```julia
Random.seed!(2019)

rf_cl = RecallFilter(ChenLiuParticles(100,
                                      prior_optimized,
                                      StickyCRP(0.01, 0.9)),
                     Matrix(0.01I,2,2))
rf_fh = RecallFilter(FearnheadParticles(100,
                                        prior_optimized,
                                        StickyCRP(0.01, 0.9)),
                     Matrix(0.01I,2,2))

filter!(rf_cl, extract_data(recall1, rf_cl))
filter!(rf_fh, extract_data(recall1, rf_fh))

rf = rf_fh

filter_sim = assignment_similarity(rf)
filter_sim_cl = assignment_similarity(rf_cl)

# outline the boundaries of the blocks in ~colors~
function outline_blocks(sim_mat, blocks, block_pallete)
    block_colors = RGB.(Gray.(sim_mat))
    nblock = length(unique(blocks))
    for n in 1:nblock
        start = findfirst(isequal(n), blocks)
        stop = findlast(isequal(n), blocks)
        color = block_pallete[n]
        block = view(block_colors, start:stop, start:stop)
        block[1:end, 1] .= color
        block[1:end, end] .= color
        block[1, 1:end] .= color
        block[end, 1:end] .= color
    end
    return block_colors
end

euc_dist = @_ recall1 |>
    @with(_, hcat(:x, :y)) |>
    Distances.pairwise(Euclidean(), _', dims=2)

# plot(plot(outline_blocks(filter_sim, recall1[:block], block_pallete),
#           title="Inferred clusters (FC)", guide="Trial"),
#      plot(outline_blocks(filter_sim_cl, recall1[:block], block_pallete),
#           title="Inferred clusters (CL)", guide="Trial"),
#      plot(outline_blocks(1 .- euc_dist ./ maximum(euc_dist),
#                          recall1[:block],
#                          block_pallete),
#           title="Euclidean distance"),
#      aspect_ratio=:equal, layout=(1,3), size=(900,300))
plot(plot(outline_blocks(filter_sim, recall1[:block], block_pallete),
          title="Inferred clusters", guide="Trial"),
     plot(outline_blocks(1 .- euc_dist ./ maximum(euc_dist),
                         recall1[:block],
                         block_pallete),
          title="Euclidean distance"),
     aspect_ratio=:equal, layout=(1,2), size=(600,300))


```

### Adjusted Rand Index

```{julia; label="adjusted-rand-index"}

@load "../results/randindex-2019-07-15T16:17:46.864.jld2" results_df

ari_summaries = by(results_df, [:α, :ρ], :ari => x -> NamedTuple{(:mean, :low, :high)}(boot_ci(x)...))

ari_bysub = by(results_df, [:α, :ρ, :subjid1], ari = :ari => mean)
ari_summaries_bysub = by(ari_bysub, [:α, :ρ], :ari => x -> NamedTuple{(:mean, :low, :high)}(boot_ci(x)...))

@df ari_summaries_bysub plot(:α, :mean, ribbon=(:mean .- :low, :high .- :mean),
                             group=:ρ, xscale=:log10, ylim=(0.75, 1.0),
                             xlabel="Eagerness to create new clusters (concentration \\alpha)",
                             ylabel=("Adjusted Rand Index with true clusters"),
                             legend=:bottomright, legend_title="Stickiness \\rho")

```

## Recall

```julia

@load "../results/run3-2019-01-07T21:23:16.243-recalled-predicted.jld2" recalled_all predicted_all

summaries_by_iter = by(recalled_all, [:α, :ρ, :Sσ, :iter]) do d
    DataFrame(cos=cosinesim(d), mse=Experiments.mse(d,d))
end

recalled_summaries = by(summaries_by_iter, [:α, :ρ, :Sσ]) do d
    # collect only necessary here because of Bootstrap.jl#42, can remove once
    # #43 is merged
    (c, clow, chigh), = boot_ci(collect(d[:cos]))
    (m, mlow, mhigh), = boot_ci(collect(d[:mse]))
    DataFrame(cos=c, cos_low=clow, cos_high=chigh,
              mse=m, mse_low=mlow, mse_high=mhigh)
end

```

```{julia; label="recall-results"}

rec_params_good = @_ recalled_summaries |>
    @where(_, :Sσ .≈ 0.01) |>
    sort!(_, :cos, rev=true) |> 
    first(_, 1) 

# average over iterations
recalled_good = @_ rec_params_good |>
    join(recalled_all, _, on=[:α, :ρ, :Sσ]) |>
    @by(_, [:subjid1, :block, :rep, :rep_number, :respnr, :rad, :var, :x, :y, :x_resp, :y_resp],
        x_mod = mean(:x_mod), y_mod = mean(:y_mod)) 

recalled1 = @_ recalled_good |>
    @where(_, :subjid1 .== one_subj)

# baselines
baseline!(df) = @_ df |>
    @transform(_, gt_rho_avg = rho.(:x,:y) .> mean(rho.(:x, :y))) |>
    # @with(_, (hcat(:x,:y) .* ifelse.(:gt_rho_avg, -1, 1))')
    @transform(_, cos_center = 1 .- Distances.colwise(CosineDist(),
                                                      -hcat(:x, :y)', 
                                                      hcat(:x_resp.-:x, :y_resp.-:y)'),
                  cos_mean_rho = 1 .- Distances.colwise(CosineDist(),
                                                        (hcat(:x,:y) .* ifelse.(:gt_rho_avg, -1, 1))',
                                                        hcat(:x_resp.-:x, :y_resp.-:y)'),
                  cos_mod = 1 .- Distances.colwise(CosineDist(),
                                                   hcat(:x_mod.-:x, :y_mod.-:y)',
                                                   hcat(:x_resp.-:x, :y_resp.-:y)'))

baseline_good = baseline!(recalled_good)
bs_center, bs_avgrho = @_ baseline_good |>
    @where(_, (!isnan).(:cos_center)) |>    # there is one trial with zero deviation...
    @with(_, (mean(:cos_center), mean(:cos_mean_rho)))

# baseline: chance responding throughout the arena:
function discuniform(n)
    θs = rand(n)' .* 2π
    ρs = sqrt.(rand(n)')
    vcat(cos.(θs) .* ρs,
         sin.(θs) .* ρs)
end

cos_rand = let xy = hcat(recall.x, recall.y)', xyresp = hcat(recall.x_resp, recall.y_resp)'
    [mean(1 .- Distances.colwise(CosineDist(),
                                 discuniform(size(xy, 2)) .- xy,
                                 xyresp .- xy))
     for _ in 1:1000]
end

```

### Example

```{julia; label="example-subj-recall"; fig_cap="Subject 4's recalled locations (gray arrows, pointing from studied to recalled location) compared with model simulation (blue arrows; \$\\alpha=0.01, \\rho=0.9, \\sigma_x=0.1\$)"}
@df recalled1 arena(:x, :y, quiver=(:x_mod .- :x, :y_mod .- :y),
                    seriestype=:quiver, label="Model")
@df recalled1 quiver!(:x, :y, quiver=(:x_resp .- :x, :y_resp .- :y),
                      color=GrayA(0.0, 0.5), label="Behavior")
```

### Quantified

```{julia; label="cosinesim-by-param"; fig_cap="Mean cosine-similarity of model predicted and actual recall deviations across parameter values (ribbons show 95% bootstrapped CIs over model runs).  Gray lines show baselines: always deviate toward center, average radius, and center of true clusters"}

@df(@where(recalled_summaries, :Sσ .≈ 0.01),
    plot(:α, :cos, ribbon = (:cos .- :cos_low, :cos_high .- :cos), group=:ρ, xscale=:log10, 
         xlims=(10^-2.5, 10^1.5), ylims=(0, 0.12), seriestype=:line,
         xlabel="Eagerness to create new clusters (concentration \\alpha)",
         ylabel=("Cosine sim. with behavior"),
         legend=:bottomleft, legend_title="Stickiness \\rho", line=2))

baseline_x = [10^-2.1, 10^1.1]

function plot_baseline!(y, label)
    plot!(baseline_x, ones(2)*y, color=Gray(0.7), label="")
    annotate!(baseline_x[end]*1.05, y, label)
end

plot_baseline!(cosinesim(known_recalled),
               text("Known\nclusters", 10, RGB(Gray(0.7)), :left, :bottom))
plot_baseline!(bs_center,
               text("Center", 10, RGB(Gray(0.7)), :left, :bottom))
plot_baseline!(bs_avgrho,
               text("Mean rad.", 10, RGB(Gray(0.7)), :left, :top))

plot!(baseline_x, ones(2)*quantile(cos_rand, 0.025), fillrange=quantile(cos_rand, 0.975),
      fillalpha=0.1, fillcolor=GrayA(0., 0.1), primary=false, linealpha=0)
annotate!(baseline_x[end]*1.05, mean(cos_rand),
          text("Random\nresponse\n(95% CI)", 10, RGB(Gray(0.7)), :left, :top))

```

```{julia; label="cosinesim-by-param-subj-cis"}

# there's a lot of variability by subjects (and small $n$ so very low power)

summaries_by_subj = by(recalled_all, [:α, :ρ, :Sσ, :subjid1]) do d
    DataFrame(cos=cosinesim(d), mse=Experiments.mse(d,d))
end

summaries_by_subj_cis = by(summaries_by_subj,
                           [:α, :ρ, :Sσ],
                           :cos => x -> NamedTuple{(:mean, :low, :high)}(boot_ci(x)...))

# @_ summaries_by_subj_cis |>
#     @where(_, :Sσ .≈ 0.01) |>
#     @df plot!(:α, :mean, ribbon = (:mean .- :low, :high .- :mean), group=:ρ, xscale=:log10,
#               fillalpha=0.1, color=(1:3)', label=["" "" ""], ylims=(0, 0.18))

@_ summaries_by_subj_cis |>
    @where(_, :Sσ .≈ 0.01) |>
    @df plot!(:α, :low, group=:ρ, xscale=:log10,
              linestyle=:dash, color=(1:3)', label=["" "" ""], ylims=(0, 0.18))

@_ summaries_by_subj_cis |>
    @where(_, :Sσ .≈ 0.01) |>
    @df plot!(:α, :high, group=:ρ, xscale=:log10,
              linestyle=:dash, color=(1:3)', label=["" "" ""], ylims=(0, 0.18))


```

## Prediction

### Examples



### Quantified

